{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show matplotlib\n",
    "# !pip show pandas\n",
    "# !pip show scikit-learn\n",
    "# !pip show seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install seaborn\n",
    "# !pip install torchinfo\n",
    "# !pip install torchviz\n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:38:21.426032Z",
     "iopub.status.busy": "2024-04-03T11:38:21.425391Z",
     "iopub.status.idle": "2024-04-03T11:38:21.432682Z",
     "shell.execute_reply": "2024-04-03T11:38:21.431659Z",
     "shell.execute_reply.started": "2024-04-03T11:38:21.426002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing PyTorch and its computer vision extension\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Importing plotting/visualization and numerical computation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torchviz import make_dot\n",
    "from graphviz import Source\n",
    "\n",
    "# Importing utilities for random operations and file/directory handling\n",
    "import random\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "# Importing data handling utilities from PyTorch and scikit-learn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing specific data preprocessing and augmentation tools from torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torchvision.datasets import MNIST\n",
    "from PIL import Image\n",
    "\n",
    "# Importing feature extraction tools and evaluation metrics\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix, multilabel_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:56.157084Z",
     "iopub.status.busy": "2024-04-03T11:10:56.156660Z",
     "iopub.status.idle": "2024-04-03T11:10:56.213513Z",
     "shell.execute_reply": "2024-04-03T11:10:56.212362Z",
     "shell.execute_reply.started": "2024-04-03T11:10:56.157049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:56.215741Z",
     "iopub.status.busy": "2024-04-03T11:10:56.215328Z",
     "iopub.status.idle": "2024-04-03T11:10:56.225374Z",
     "shell.execute_reply": "2024-04-03T11:10:56.224723Z",
     "shell.execute_reply.started": "2024-04-03T11:10:56.215707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original transformation\n",
    "original_transform = transforms.Compose([\n",
    "    \n",
    "    # Resize input images to a fixed size of 224x224 pixels\n",
    "    transforms.Resize((224, 224)),  \n",
    "    \n",
    "    # Converts the image data into PyTorch tensors\n",
    "    transforms.ToTensor(), \n",
    "    \n",
    "    # Standardize input data by subtracting the mean and dividing by the standard deviation along each channel (RGB)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n",
    "])\n",
    "\n",
    "# Augmented transformation with horizontal flip and random rotation\n",
    "augmented_transform = transforms.Compose([\n",
    "    \n",
    "    # Resize input images to a fixed size of 224x224 pixels\n",
    "    transforms.Resize((224, 224)),\n",
    "    \n",
    "    # Randomly flips the images horizontally with a probability of 1.0\n",
    "    transforms.RandomHorizontalFlip(p=1.0), \n",
    "    \n",
    "    # Randomly rotate images in the range of -15 to +15 degrees\n",
    "    transforms.RandomRotation(degrees=15), \n",
    "    \n",
    "    # Converts the augmented images into PyTorch tensors\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Standardize input data by subtracting the mean and dividing by the standard deviation along each channel (RGB)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:56.228486Z",
     "iopub.status.busy": "2024-04-03T11:10:56.228091Z",
     "iopub.status.idle": "2024-04-03T11:10:56.825017Z",
     "shell.execute_reply": "2024-04-03T11:10:56.824133Z",
     "shell.execute_reply.started": "2024-04-03T11:10:56.228462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset from local folder, without applying any transformations\n",
    "raw_dataset = datasets.ImageFolder(root='dataset', transform=None)\n",
    "\n",
    "# Load the dataset from Kaggle, without applying transformations\n",
    "# raw_dataset = datasets.ImageFolder(root='/kaggle/input/the-iqothnccd-lung-cancer-dataset', transform=None)\n",
    "\n",
    "# print(raw_dataset)\n",
    "# print(\"---\")\n",
    "# print(raw_dataset[0])\n",
    "# print(\"---\")\n",
    "# print(type(raw_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first raw image and its label directly\n",
    "# img, label = raw_dataset[0]\n",
    "raw_img, label = raw_dataset[0]\n",
    "\n",
    "# Now apply the orignal and augmented transformations to the raw PIL image for demonstration\n",
    "img_original_tensor = original_transform(raw_img)\n",
    "img_augmented_tensor = augmented_transform(raw_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:56.826525Z",
     "iopub.status.busy": "2024-04-03T11:10:56.826163Z",
     "iopub.status.idle": "2024-04-03T11:10:57.449325Z",
     "shell.execute_reply": "2024-04-03T11:10:57.448218Z",
     "shell.execute_reply.started": "2024-04-03T11:10:56.826494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the function to unnormalize and show the image\n",
    "def show_image(img, title=None, ax=None):\n",
    "    \n",
    "    # Convert image tensor from PyTorch tensor format to NumPy array format. Transpose the dimensions to re-arrange order of axes\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Define the mean and standard deviations values used (when normalizing)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Reverse the normalization applied during data preprocessing.\n",
    "    img = std * img + mean  \n",
    "    \n",
    "    # Clips the pixel values of the image array to ensure that they fall within the valid range of [0, 1]\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    # If axis is provided, plot image on specified axis, else plot using image dimensions\n",
    "    if ax is not None:\n",
    "        ax.imshow(img)\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.pause(0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for display: Creates a figure and a set of subplots arranged in a single row with two columns and figure size as 12 inches by 6 inches wide. \n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Displaying the original image and the augmented image\n",
    "show_image(img_original_tensor, title='Original Image', ax=axs[0])\n",
    "show_image(img_augmented_tensor, title='Augmented Image', ax=axs[1])\n",
    "\n",
    "# Displaying the entire figure containing both subplots with the original and augmented images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from local folder, applying transformations this time\n",
    "dataset = datasets.ImageFolder(root='dataset', transform = augmented_transform)\n",
    "\n",
    "# Load the dataset from Kaggle, applying transformations this time\n",
    "# dataset = datasets.ImageFolder(root='/kaggle/input/the-iqothnccd-lung-cancer-dataset', transform=augmented_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display list of tuples, where each tuple contains the file path to an image and its corresponding class label\n",
    "dataset.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:57.451472Z",
     "iopub.status.busy": "2024-04-03T11:10:57.450739Z",
     "iopub.status.idle": "2024-04-03T11:10:57.482356Z",
     "shell.execute_reply": "2024-04-03T11:10:57.481599Z",
     "shell.execute_reply.started": "2024-04-03T11:10:57.451436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset - 70% for training, 15% for validation and the rest 15% for testing\n",
    "train_size = int(0.7 * len(dataset)) \n",
    "val_size = int(0.15 * len(dataset)) \n",
    "test_size = len(dataset) - train_size - val_size \n",
    "\n",
    "# Extracting labels from the dataset\n",
    "targets = [s[1] for s in dataset.samples]  \n",
    "\n",
    "# Splitting the dataset into 2 sets: train+val and test sets\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    # The array which we want to split\n",
    "    range(len(targets)),\n",
    "    # Specify proportion of the dataset that should be allocated for the test set \n",
    "    test_size= test_size/len(dataset), \n",
    "    # Ensure class distribution is preserved in both the training+validation and testing sets\n",
    "    stratify=targets,\n",
    "    # random seed for reproducibility\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# Splitting the train+val further into 2 sets: training and validation sets\n",
    "train_idx, val_idx = train_test_split(\n",
    "    # The array which we want to split\n",
    "    train_val_idx,\n",
    "    # Specify proportion of the dataset that should be allocated for the validation set \n",
    "    test_size=val_size / (train_size + val_size),  \n",
    "    # Ensure class distribution is preserved for both the training and validation set\n",
    "    stratify=[targets[i] for i in train_val_idx],\n",
    "    # random seed for reproducibility\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# Creating subsets for each split\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "validation_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(validation_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loaders that help iterate through the dataset in batches during training, validation and testing.\n",
    "# Using a batch size of 16 everywhere and only shuffling during training and not validation or testing.\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "test_loader_for_inference = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_loader)\n",
    "# testing_loop = 0\n",
    "\n",
    "# for inputs, labels in train_loader:\n",
    "#     print(f\"Iteration number {testing_loop}\")\n",
    "#     print(\"Inputs\")\n",
    "#     print(inputs)\n",
    "#     print(\"Size of inputs\")\n",
    "#     print(inputs.size())\n",
    "#     print(\"Labels\")\n",
    "#     print(labels)\n",
    "#     print(\"=========\")\n",
    "#     testing_loop += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:57.483889Z",
     "iopub.status.busy": "2024-04-03T11:10:57.483558Z",
     "iopub.status.idle": "2024-04-03T11:10:57.495307Z",
     "shell.execute_reply": "2024-04-03T11:10:57.494306Z",
     "shell.execute_reply.started": "2024-04-03T11:10:57.483861Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN_for_LungCancer(nn.Module):\n",
    "    def __init__(self, dropout_rate, fc_units):\n",
    "        \n",
    "        # Initialize base class, nn.Module\n",
    "        super(CNN_for_LungCancer, self).__init__()\n",
    "        \n",
    "        # First convolutional layer with 3 input channels (RGB images), 32 output channels, 3x3 kernel size, and 1 pixel padding\n",
    "        # Note: Width & Height don't change as padding is 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Batch normalization \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # ReLu Activation\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        # Max pooling with 2*2 kernel size and stride of 2\n",
    "        # Note: The Width & Height will be halved here, as stride is 2, with 2*2 kernel size (skipping over alternate columns)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Dropout layer applied after the first pooling layer\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)  \n",
    "        \n",
    "        # Second convolutional layer with 32 input channels (output from the previous layer), 64 output channels, 3x3 kernel size, and 1 pixel padding\n",
    "        # Note: Width & Height don't change as padding is 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        \n",
    "        # ReLu Activation\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        # Dropout layer applied after the second pooling layer\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)   \n",
    "        \n",
    "        # Commented - 3rd Convolutional Layer\n",
    "        #self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        #self.bn3 = nn.BatchNorm2d(128)\n",
    "        #self.act3 = nn.ReLU()\n",
    "        #self.dropout3 = nn.Dropout(dropout_rate)  \n",
    "        #self.fc1 = nn.Linear(in_features=128 * 28 * 28, out_features=fc_units)\n",
    "        \n",
    "        # First fully connected of neural network, with fc_units number of output features/neurons in the fully connected layer\n",
    "        self.fc1 = nn.Linear(in_features = 64 * 56 * 56, out_features = fc_units)\n",
    "        \n",
    "        # Second fully connected layer with 3 output features for classification (benign, malignant, and normal)\n",
    "        self.fc2 = nn.Linear(fc_units, 3)\n",
    "        \n",
    "        # Final dropout layer with specified dropout rate\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Applies the first convolutional layer, then ReLU activation function, then batch normalization and max pooling\n",
    "        x = self.pool(self.bn1(self.act1(self.conv1(x))))\n",
    "        \n",
    "        # Applies dropout to output of the first pooling layer\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Applies the second convolutional layer, then ReLU activation function, then batch normalization and max pooling\n",
    "        x = self.pool(self.bn2(self.act2(self.conv2(x))))\n",
    "        \n",
    "        # Applies dropout to output of the second pooling layer\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        #x = self.pool(self.bn3(self.act3(self.conv3(x))))\n",
    "        #x = self.dropout3(x)\n",
    "        \n",
    "        # Prepare data for input into fully-connected layers by flattening output of the last pooling layer into a 1-dimensional tensor\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Applies dropout to the output of the first fully connected layer \n",
    "        x = self.dropout4(self.fc1(x))\n",
    "        \n",
    "        # Computes the final output of the neural network by passing the output of the first fully connected layer through the second fully connected layer\n",
    "        # This represents class scores for each input sample\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:57.496823Z",
     "iopub.status.busy": "2024-04-03T11:10:57.496520Z",
     "iopub.status.idle": "2024-04-03T11:10:57.849996Z",
     "shell.execute_reply": "2024-04-03T11:10:57.849037Z",
     "shell.execute_reply.started": "2024-04-03T11:10:57.496798Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pass dropout rate of 0.5 and 64 neurons in first fully connected layer\n",
    "cnn_model = CNN_for_LungCancer(dropout_rate=0.5, fc_units=64)\n",
    "cnn_model.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(cnn_model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining CNN + LSTM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM_for_LungCancer(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout_rate, fc_units, lstm_units, num_layers):\n",
    "        \n",
    "        super(CNN_LSTM_for_LungCancer, self).__init__()\n",
    "        \n",
    "        \n",
    "        ## CNN Part\n",
    "        \n",
    "        \n",
    "        # First convolutional layer with 3 input channels (RGB images), 32 output channels, 3x3 kernel size, and 1 pixel padding\n",
    "        # Note: Width & Height don't change as padding is 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # ReLu Activation\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        # Max pooling with 2*2 kernel size and stride of 2\n",
    "        # Note: The Width & Height will be halved here, as stride is 2, with 2*2 kernel size (skipping over alternate columns)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Dropout layer applied after the first pooling layer\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Second convolutional layer with 32 input channels (output from the previous layer), 64 output channels, 3x3 kernel size, and 1 pixel padding\n",
    "        # Note: Width & Height don't change as padding is 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # ReLu Activation\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        # Dropout layer applied after the second pooling layer\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## LSTM Part\n",
    "        \n",
    "        \n",
    "        # Obtain inputs of flattened size of 64 * 56 (dimensions after the CNN layers), with tensors in a batch first manner\n",
    "        self.lstm = nn.LSTM(input_size=64 * 56, hidden_size=lstm_units, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Apply dropout to output of LSTM layer for regularization\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # First Fully Connected Layer mapping output of the LSTM layer to a lower-dimensional space with fc_units neurons\n",
    "        self.fc1 = nn.Linear(lstm_units, fc_units)  \n",
    "        \n",
    "        # Second Fully Connected Layer mapping output of the previous fully connected layer to the final output space with 3 classes\n",
    "        self.fc2 = nn.Linear(fc_units, 3)  \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        ## CNN Part\n",
    "        \n",
    "        \n",
    "        # Applies the first convolutional layer, then ReLU activation function, then batch normalization and max pooling\n",
    "        x = self.pool(self.bn1(self.act1(self.conv1(x))))\n",
    "        \n",
    "        # Applies dropout to output of the first pooling layer\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Applies the second convolutional layer, then ReLU activation function, then batch normalization and max pooling\n",
    "        x = self.pool(self.bn2(self.act2(self.conv2(x))))\n",
    "        \n",
    "        # Applies dropout to output of the second pooling layer\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # At the end of CNN, the dimensions would be:\n",
    "        # (batch_size, channels, height, width)\n",
    "        \n",
    "        \n",
    "        ## Prepare for LSTM\n",
    "        \n",
    "        \n",
    "        # Swap the second dimension (channels) with third dimension (height) so it becomes (batch_size, height, channels, width)\n",
    "        # This is because the sequence length of LSTM needs to be the height of the images \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  \n",
    "        \n",
    "        # Load x.size() as such \n",
    "        batch_size, seq_len, channels, height = x.size()\n",
    "        \n",
    "        # Reshape the last input_size dimensions\n",
    "        x = x.view(batch_size, seq_len, -1)  \n",
    "        \n",
    "        \n",
    "        ## LSTM Part\n",
    "        \n",
    "        \n",
    "        # Pass input tensor, x to the model. \n",
    "        # Returns output of LSTM layer at each time step, along with a tuple of hidden state and cell state of LSTM at last time step\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Applying dropout to this selected hidden state of the LSTM at the last time step for each sample in the batch, as we are only interested in final output\n",
    "        x = self.dropout3(x[:, -1, :])  \n",
    "        \n",
    "        # Utilizing the 2 Fully Connected Layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 256  \n",
    "num_layers = 2  \n",
    "\n",
    "# Instantiating the CNN+LSTM model\n",
    "CNN_LSTM_model = CNN_LSTM_for_LungCancer(dropout_rate = 0.25, fc_units = 64, lstm_units = lstm_units, num_layers = num_layers)\n",
    "CNN_LSTM_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(CNN_LSTM_model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Training & Evaluating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, train_loader, validation_loader, test_loader, epochs=10, lr=0.0001, early_stopping_patience = 5, lr_scheduler_patience = 10):\n",
    "    \n",
    "    # Initialize lists to store accuracies and losses for train, test and validation\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    # Initialize the early stopping parameters\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = deepcopy(model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    # Move device to GPU if available, else CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "        \n",
    "    # Computes Loss Function using Cross Entropy Loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize Adam Optimizer with certain parameters \n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           # Set learning rate of the optimizer\n",
    "                           lr = lr,\n",
    "                           # Set L2 regularization to the model's weights during optimization\n",
    "                           weight_decay = 1e-4, \n",
    "                           # Defining beta1 (first moment) as 0.9 and beta2 (second moment) as 0.999\n",
    "                           betas = (0.9, 0.999),\n",
    "                           # Epsilon to ensure numerical stability during optimization\n",
    "                           eps = 1e-8,\n",
    "                           # Adopting AMSGrad variant of the Adam optimizer\n",
    "                           amsgrad = True)\n",
    "    \n",
    "    print(optimizer)\n",
    "    \n",
    "    # Initialize the learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience = lr_scheduler_patience, verbose = True, threshold = 0.0001, threshold_mode = 'rel', cooldown = 0, min_lr = 0, eps = 1e-8)\n",
    "    \n",
    "    # Running the algorithm for specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        \n",
    "        ## TRAINING\n",
    "        \n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Keeps track of training loss\n",
    "        train_loss = 0\n",
    "        \n",
    "        # Correct_train keeps track of the number of correctly predicted samples during training\n",
    "        correct_train = 0\n",
    "        \n",
    "        # Total_train keeps track of the number of the total number of training samples processed so far \n",
    "        total_train = 0\n",
    "        \n",
    "        # For each input data and label in training dataset\n",
    "        for inputs, labels in train_loader:\n",
    "            \n",
    "            # Move it to the right device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        \n",
    "            # Set all calculated gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # If model being trained is GoogleNet and it is in training mode, then initialize it differently (due to auxiliary outputs), as follows:\n",
    "            if model_name == \"GoogleNet_Model\" and model.training:\n",
    "                \n",
    "                # Perform forward pass through the network with given inputs\n",
    "                # Note: Inception v3 model returns outputs in the form of (output, aux_logits) during training\n",
    "                outputs, aux_outputs = model(inputs)\n",
    "                \n",
    "                # Calculates loss of main output and loss of auxiliary output\n",
    "                loss1 = criterion(outputs, labels)\n",
    "                loss2 = criterion(aux_outputs, labels)\n",
    "                \n",
    "                # Combine main loss and auxiliary loss to get final loss of GoogleNet (a weighted average of the two losses)\n",
    "                loss = loss1 + 0.4 * loss2\n",
    "                \n",
    "            else:\n",
    "                # Perform forward pass through the network with given inputs\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Obtain loss value \n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Compute the gradients of the loss with respect to all trainable parameters in the model.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the model parameters based on the computed gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulates the value of the loss incurred in the current batch to the overall training loss.\n",
    "            # Note: .item() extracts scalar value\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Obtain the class predicted by the model\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update total_train to keep track of the total number of training samples processed so far\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            # Update correct_train to keep track of the number of correctly predicted samples in the current batch\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate train_accuracy\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        \n",
    "        # Append the training accuracy to train_accuracies list to monitor it over epochs\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Append the training loss to train_losses list to monitor it over epochs\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        \n",
    "        \n",
    "        ## VALIDATION\n",
    "\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Correct_validation keeps track of the number of correctly predicted samples during validation\n",
    "        correct_validation = 0\n",
    "        \n",
    "        # Total_validation keeps track of the number of total samples during validation\n",
    "        total_validation = 0\n",
    "        \n",
    "        # Validation_loss keeps track of total loss during evaluation on the validation set\n",
    "        validation_loss = 0\n",
    "        \n",
    "        # During validation, we don't need to utilize gradient\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # For each input data and label in validation dataset\n",
    "            for inputs, labels in validation_loader:\n",
    "                \n",
    "                # Move it to the right device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Trigger a forward pass through the neural network\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compare the outputs (predictions made by the model) and the labels (ground truth data) wrt to loss function\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Accumulates the value of the loss incurred in the current batch to the overall validation loss.\n",
    "                # Note: .item() extracts scalar value\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "                # Obtain the class predicted by the model\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Update total_validation to keep track of the total number of validation samples processed so far\n",
    "                total_validation += labels.size(0)\n",
    "                \n",
    "                # Update correct_validation to keep track of the number of correctly predicted samples in the current batch\n",
    "                correct_validation += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate validation_accuracy\n",
    "        validation_accuracy = 100 * correct_validation / total_validation\n",
    "        \n",
    "        # Append the validation accuracy to validation_accuracies list to monitor it over epochs\n",
    "        validation_accuracies.append(validation_accuracy)\n",
    "        \n",
    "        # Append the validation loss to validation_losses list to monitor it over epochs\n",
    "        validation_losses.append(validation_loss / len(validation_loader))\n",
    "\n",
    "        \n",
    "        # Step the learning rate scheduler based on validation loss\n",
    "        scheduler.step(validation_loss)\n",
    "        \n",
    "        \n",
    "        ## Early stopping logic\n",
    "        \n",
    "        # Retrieve the most recent validation loss\n",
    "        current_val_loss = validation_losses[-1]\n",
    "        \n",
    "        # If current validation loss is lower than the best validation loss, it means model has improved\n",
    "        if current_val_loss < best_val_loss:\n",
    "            \n",
    "            # Set the new best validation loss as the current valiation loss\n",
    "            best_val_loss = current_val_loss\n",
    "            \n",
    "            # Copy all the parameters of the current model and save it to best_modeL_state variable\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            \n",
    "            # Reset epochs_no_improve variable to 0\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Increment the epochs_no_improve\n",
    "            epochs_no_improve += 1\n",
    "            \n",
    "            # Check if epochs_no_improve has reached the patience threshold (hyperparameter). \n",
    "            # If yes, it will break the epoch loop and save weights of the model at the end\n",
    "            if epochs_no_improve == early_stopping_patience:\n",
    "                print(f'Early stopping triggered after {epoch + 1} epochs!')\n",
    "                break\n",
    "                \n",
    "                \n",
    "        ## TESTING\n",
    "        \n",
    "        # These are the lists to collect all true labels and predictions\n",
    "        all_test_labels = []\n",
    "        all_test_predictions = []\n",
    "        \n",
    "        # Keeps track of testing loss\n",
    "        test_loss = 0 \n",
    "        \n",
    "        # Keeps track of the number of correctly predicted samples during testing\n",
    "        correct_test = 0\n",
    "        \n",
    "        # Total_test keeps track of the number of the total number of testing samples processed so far \n",
    "        total_test = 0\n",
    "        \n",
    "        # During testing, we don't need to utilize gradient\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # For each input data and label in test dataset\n",
    "            for inputs, labels in test_loader:\n",
    "                \n",
    "                # Move it to the right device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Trigger a forward pass through the neural network\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compare the outputs (predictions made by the model) and the labels (ground truth data) wrt to loss function\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Accumulates the value of the loss incurred in the current batch to the overall testing loss.\n",
    "                # Note: .item() extracts scalar value\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Obtain the class predicted by the model\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Save the labels and predictions to lists\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "                all_test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                # Update total_test to keep track of the total number of testing samples processed so far\n",
    "                total_test += labels.size(0)\n",
    "                \n",
    "                # Append the testing loss to correct_test list to monitor it over epochs\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate testing accuracy\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        \n",
    "        # Append the testing accuracy to test_accuracies list to monitor it over epochs\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        # Append the testing loss to test_losses list to monitor it over epochs\n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "              f\"Validation Loss: {validation_loss/len(validation_loader):.4f}, \"\n",
    "              f\"Test Loss: {test_loss/len(test_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Validation Accuracy: {validation_accuracy:.2f}%, \"\n",
    "              f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        print(\"--------------------------------------------------------------\")\n",
    "        \n",
    "        #print(f\"Epoch number {epoch+1}:\")\n",
    "        #print(\"Model dictionary at that epoch\")\n",
    "        \n",
    "        #print(model.state_dict())\n",
    "        \n",
    "        #for param_tensor in model.state_dict():\n",
    "            #print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "            \n",
    "        print(\"--------------------------------------------------------------\")\n",
    "\n",
    "       \n",
    "    ## This is after the epoch loop\n",
    "    print(f\"Best validation loss obtained for particular epoch: {best_val_loss}\")\n",
    "    \n",
    "    # Load the best model state (from the best epoch). This will be the one corresponding to the lowest (best) validation loss\n",
    "    model.load_state_dict(best_model_state) \n",
    "    \n",
    "    #print(\"Loaded Model dictionary\")\n",
    "    \n",
    "    #print(model.state_dict())\n",
    "    \n",
    "#     if model_name == \"Custom_CNN_Model\":\n",
    "#         print(\"Saving CNN Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_cnn_model.pth\")\n",
    "\n",
    "#     if model_name == \"ResNet_Model\":\n",
    "#         print(\"Saving ResNet Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_resnet_model.pth\")\n",
    "\n",
    "#     if model_name == \"VGGNet_Model\":\n",
    "#         print(\"Saving VGGNet Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_vgg19net_model.pth\")\n",
    "                                  \n",
    "#     if model_name == \"DenseNet_Model\":\n",
    "#         print(\"Saving DenseNet Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_DenseNet161_model.pth\")\n",
    "        \n",
    "#     if model_name == \"MobileNet_Model\":\n",
    "#         print(\"Saving MobileNetV3 Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_MobileNetV3_model.pth\")\n",
    "        \n",
    "#     if model_name == \"Wide_ResNet_Model\":\n",
    "#         print(\"Saving MobileNetV3 Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_WideResNet_model.pth\")\n",
    "        \n",
    "#     if model_name == \"AlexNet_Model\":\n",
    "#         print(\"Saving AlexNet Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_AlexNet_model.pth\")\n",
    "        \n",
    "#     if model_name == \"GoogleNet_Model\":\n",
    "#         print(\"Saving GoogleNet Model\")\n",
    "#         torch.save(model.state_dict(), \"train/weights/lung_cancer_classification_GoogleNet_model.pth\")\n",
    "        \n",
    "    # Convert the all_test_labels and all_test_predictions lists to numpy arrays\n",
    "    all_test_labels = np.array(all_test_labels)\n",
    "    all_test_predictions = np.array(all_test_predictions)\n",
    "\n",
    "    return train_accuracies, test_accuracies, validation_accuracies, train_losses, test_losses, validation_losses, all_test_labels, all_test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating CNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:10:57.878037Z",
     "iopub.status.busy": "2024-04-03T11:10:57.877771Z",
     "iopub.status.idle": "2024-04-03T11:12:52.613923Z",
     "shell.execute_reply": "2024-04-03T11:12:52.612962Z",
     "shell.execute_reply.started": "2024-04-03T11:10:57.878015Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_accuracies_cnn, test_accuracies_cnn, validation_accuracies_cnn, train_losses_cnn, test_losses_cnn, validation_losses_cnn, all_test_labels_cnn, all_test_predictions_cnn = train_and_evaluate(model = cnn_model, model_name = \"Custom_CNN_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs=10, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training accuracies: {train_accuracies_cnn} \\n\")\n",
    "print(f\"Testing accuracies: {test_accuracies_cnn} \\n\")\n",
    "print(f\"Validation accuracies: {validation_accuracies_cnn} \\n\")\n",
    "print(f\"Training loses: {train_losses_cnn} \\n\")\n",
    "print(f\"Testing loses: {test_losses_cnn} \\n\")\n",
    "print(f\"Validation loses: {validation_losses_cnn} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:12:52.615926Z",
     "iopub.status.busy": "2024-04-03T11:12:52.615582Z",
     "iopub.status.idle": "2024-04-03T11:12:52.961878Z",
     "shell.execute_reply": "2024-04-03T11:12:52.960951Z",
     "shell.execute_reply.started": "2024-04-03T11:12:52.615896Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_cnn, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_cnn, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_cnn, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of CNN Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T11:12:52.963363Z",
     "iopub.status.busy": "2024-04-03T11:12:52.963056Z",
     "iopub.status.idle": "2024-04-03T11:12:53.289876Z",
     "shell.execute_reply": "2024-04-03T11:12:53.288910Z",
     "shell.execute_reply.started": "2024-04-03T11:12:52.963338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_cnn, label='Train Loss')\n",
    "plt.plot(test_losses_cnn, label='Test Loss')\n",
    "plt.plot(validation_losses_cnn, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of CNN Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_test_labels_cnn, all_test_predictions_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_test_labels_cnn, all_test_predictions_cnn)\n",
    "\n",
    "# Define class names (if available)\n",
    "class_names = ['Benign (Class 0)', 'Malignant (Class 1)', 'Normal (Class 2)'] \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating CNN+LSTM Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_accuracies_cnn_lstm, test_accuracies_cnn_lstm, validation_accuracies_cnn_lstm, train_losses_cnn_lstm, test_losses_cnn_lstm, validation_losses_cnn_lstm, all_test_labels_cnn_lstm, all_test_predictions_cnn_lstm = train_and_evaluate(model = cnn_model, model_name = \"Custom_CNN_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs=10, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training accuracies: {train_accuracies_cnn_lstm} \\n\")\n",
    "print(f\"Testing accuracies: {test_accuracies_cnn_lstm} \\n\")\n",
    "print(f\"Validation accuracies: {validation_accuracies_cnn_lstm} \\n\")\n",
    "print(f\"Training loses: {train_losses_cnn_lstm} \\n\")\n",
    "print(f\"Testing loses: {test_losses_cnn_lstm} \\n\")\n",
    "print(f\"Validation loses: {validation_losses_cnn_lstm} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_cnn_lstm, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_cnn_lstm, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_cnn_lstm, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of CNN+LSTM Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_cnn_lstm, label='Train Loss')\n",
    "plt.plot(test_losses_cnn_lstm, label='Test Loss')\n",
    "plt.plot(validation_losses_cnn_lstm, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of CNN + LSTM Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_test_labels_cnn_lstm, all_test_predictions_cnn_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_test_labels_cnn_lstm, all_test_predictions_cnn_lstm)\n",
    "\n",
    "# Define class names (if available)\n",
    "class_names = ['Benign (Class 0)', 'Malignant (Class 1)', 'Normal (Class 2)'] \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating ResNet Model:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-trained models can be found at: https://pytorch.org/vision/0.9/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet model\n",
    "resnet_model = models.resnet152(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(resnet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create summary of ResNet model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(resnet_model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for the 3 classes: benign, malignant, normal\n",
    "num_features = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_features, 3)\n",
    "resnet_model = resnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_resnet, test_accuracies_resnet, validation_accuracies_resnet, train_losses_resnet, test_losses_resnet, validation_losses_resnet, all_test_labels_resnet, all_test_predictions_resnet = train_and_evaluate(model = resnet_model, model_name = \"ResNet_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs=10, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_resnet, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_resnet, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_resnet, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of ResNet Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_resnet, label='Train Loss')\n",
    "plt.plot(test_losses_resnet, label='Test Loss')\n",
    "plt.plot(validation_losses_resnet, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of ResNet Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_test_labels_resnet, all_test_predictions_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_test_labels_resnet, all_test_predictions_resnet)\n",
    "\n",
    "# Define class names (if available)\n",
    "class_names = ['Benign (Class 0)', 'Malignant (Class 1)', 'Normal (Class 2)'] \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating VGG Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG-19 model with batch normalization\n",
    "vgg19_bn = models.vgg19_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(vgg19_bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of VGG-19 model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(vgg19_bn, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for the 3 classes: benign, malignant, normal\n",
    "num_classes = 3\n",
    "vgg19_bn.classifier[6] = nn.Linear(vgg19_bn.classifier[6].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_vgg19_bn, test_accuracies_vgg19_bn, validation_accuracies_vgg19_bn, train_losses_vgg19_bn, test_losses_vgg19_bn, validation_losses_vgg19_bn, all_test_labels_vgg19_bn, all_test_predictions_vgg19_bn = train_and_evaluate(model = vgg19_bn, model_name = \"VGGNet_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs = 10, lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_vgg19_bn, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_vgg19_bn, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_vgg19_bn, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of VGG-19 Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_vgg19_bn, label='Train Loss')\n",
    "plt.plot(test_losses_vgg19_bn, label='Test Loss')\n",
    "plt.plot(validation_losses_vgg19_bn, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of VGG-19 Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_test_labels_vgg19_bn, all_test_predictions_vgg19_bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_test_labels_vgg19_bn, all_test_predictions_vgg19_bn)\n",
    "\n",
    "# Define class names (if available)\n",
    "class_names = ['Benign (Class 0)', 'Malignant (Class 1)', 'Normal (Class 2)'] \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating DenseNet 161 Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained DenseNet model\n",
    "densenet_model = models.densenet161(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(densenet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of DenseNet model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(densenet_model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for the 3 classes: benign, malignant, normal\n",
    "num_classes = 3\n",
    "densenet_model.classifier = nn.Linear(densenet_model.classifier.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_densenet_model, test_accuracies_densenet_model, validation_accuracies_densenet_model, train_losses_densenet_model, test_losses_densenet_model, validation_losses_densenet_model, all_test_labels_densenet_model, all_test_predictions_densenet_model = train_and_evaluate(model = densenet_model, model_name = \"DenseNet_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs = 10, lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_densenet_model, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_densenet_model, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_densenet_model, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of Densenet-161 Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_densenet_model, label='Train Loss')\n",
    "plt.plot(test_losses_densenet_model, label='Test Loss')\n",
    "plt.plot(validation_losses_densenet_model, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of Densenet-161 Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_test_labels_densenet_model, all_test_predictions_densenet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_test_labels_densenet_model, all_test_predictions_densenet_model)\n",
    "\n",
    "# Define class names (if available)\n",
    "class_names = ['Benign (Class 0)', 'Malignant (Class 1)', 'Normal (Class 2)'] \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating MobileNet V3 Large Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNetV3-Large model\n",
    "mobilenet_model = models.mobilenet_v3_large(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mobilenet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of MobileNet model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(mobilenet_model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for the 3 classes: benign, malignant, normal\n",
    "num_classes = 3\n",
    "mobilenet_model.classifier[3] = nn.Linear(mobilenet_model.classifier[3].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_mobilenet_model, test_accuracies_mobilenet_model, validation_accuracies_mobilenet_model, train_losses_mobilenet_model, test_losses_mobilenet_model, validation_losses_mobilenet_model, all_test_labels_mobilenet_model, all_test_predictions_mobilenet_model = train_and_evaluate(model = mobilenet_model, model_name = \"MobileNet_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs = 10, lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_mobilenet_model, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_mobilenet_model, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_mobilenet_model, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of MobileNet V3 Large Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_mobilenet_model, label='Train Loss')\n",
    "plt.plot(test_losses_mobilenet_model, label='Test Loss')\n",
    "plt.plot(validation_losses_mobilenet_model, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of MobileNet V3 Large Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_test_labels_mobilenet_model, all_test_predictions_mobilenet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_test_labels_mobilenet_model, all_test_predictions_mobilenet_model)\n",
    "\n",
    "# Define class names (if available)\n",
    "class_names = ['Benign (Class 0)', 'Malignant (Class 1)', 'Normal (Class 2)'] \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating Wide ResNet-101-2\tmodel:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Wide ResNet-101-2 model\n",
    "wide_resnet_model = models.wide_resnet101_2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wide_resnet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of Wide ResNet model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(wide_resnet_model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for the 3 classes: benign, malignant, normal\n",
    "num_classes = 3\n",
    "wide_resnet_model.fc = nn.Linear(wide_resnet_model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_wide_resnet_model, test_accuracies_wide_resnet_model, validation_accuracies_wide_resnet_model, train_losses_wide_resnet_model, test_losses_wide_resnet_model, validation_losses_wide_resnet_model, all_test_labels_wide_resnet_model, all_test_predictions_wide_resnet_model = train_and_evaluate(model = wide_resnet_model, model_name = \"Wide_ResNet_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs = 10, lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_wide_resnet_model, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_wide_resnet_model, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_wide_resnet_model, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of Wide ResNet-101-2 Large Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_wide_resnet_model, label='Train Loss')\n",
    "plt.plot(test_losses_wide_resnet_model, label='Test Loss')\n",
    "plt.plot(validation_losses_wide_resnet_model, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of MobileNet V3 Large Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_test_labels_wide_resnet_model, all_test_predictions_wide_resnet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_test_labels_wide_resnet_model, all_test_predictions_wide_resnet_model)\n",
    "\n",
    "# Define class names (if available)\n",
    "class_names = ['Benign (Class 0)', 'Malignant (Class 1)', 'Normal (Class 2)'] \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating AlexNet model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained AlexNet model\n",
    "alexnet_model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(alexnet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of AlexNet model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(alexnet_model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for the 3 classes: benign, malignant, normal\n",
    "num_classes = 3\n",
    "alexnet_model.classifier[6] = nn.Linear(alexnet_model.classifier[6].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_alexnet_model, test_accuracies_alexnet_model, validation_accuracies_alexnet_model, train_losses_alexnet_model, test_losses_alexnet_model, validation_losses_alexnet_model, all_test_labels_alexnet_model, all_test_predictions_alexnet_model = train_and_evaluate(model = alexnet_model, model_name == \"AlexNet_Model\", train_loader = train_loader, validation_loader = validation_loader, test_loader = test_loader, epochs = 10, lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_alexnet_model, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_alexnet_model, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_alexnet_model, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of AlexNet Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_alexnet_model, label='Train Loss')\n",
    "plt.plot(test_losses_alexnet_model, label='Test Loss')\n",
    "plt.plot(validation_losses_alexnet_model, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of AlexNet Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating GoogleNet Model:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogleNet requires images of input size of 299x299 pixels, hence we need to change the resize in the augmented transform function and reload data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented transformation with horizontal flip and random rotation\n",
    "augmented_transform_GoogleNet = transforms.Compose([\n",
    "    \n",
    "    # Resize input images to a fixed size of 299 * 299 pixels\n",
    "    transforms.Resize((299, 299)),\n",
    "    \n",
    "    # Randomly flips the images horizontally with a probability of 1.0\n",
    "    transforms.RandomHorizontalFlip(p = 1.0), \n",
    "    \n",
    "    # Randomly rotate images in the range of -15 to +15 degrees\n",
    "    transforms.RandomRotation(degrees = 15), \n",
    "    \n",
    "    # Converts the augmented images into PyTorch tensors\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Standardize input data by subtracting the mean and dividing by the standard deviation along each channel (RGB)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from local folder, without applying any transformations \n",
    "dataset_GoogleNet = datasets.ImageFolder(root='data', transform = augmented_transform_GoogleNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset - 70% for training, 15% for validation and the rest 15% for testing\n",
    "train_size_GoogleNet = int(0.7 * len(dataset_GoogleNet)) \n",
    "val_size_GoogleNet = int(0.15 * len(dataset_GoogleNet)) \n",
    "test_size_GoogleNet = len(dataset_GoogleNet) - train_size_GoogleNet - val_size_GoogleNet \n",
    "\n",
    "# Extracting labels from the dataset\n",
    "targets_GoogleNet = [s[1] for s in dataset_GoogleNet.samples]  \n",
    "\n",
    "# Splitting the dataset into 2 sets: train+val and test sets\n",
    "train_val_idx_GoogleNet, test_idx_GoogleNet = train_test_split(\n",
    "    # The array which we want to split\n",
    "    range(len(targets_GoogleNet)),\n",
    "    # Specify proportion of the dataset that should be allocated for the test set \n",
    "    test_size = test_size_GoogleNet/len(dataset_GoogleNet), \n",
    "    # Ensure class distribution is preserved in both the training+validation and testing sets\n",
    "    stratify = targets_GoogleNet,\n",
    "    # random seed for reproducibility\n",
    "    random_state = 42  \n",
    ")\n",
    "\n",
    "# Splitting the train+val further into 2 sets: training and validation sets\n",
    "train_idx_GoogleNet, val_idx_GoogleNet = train_test_split(\n",
    "    # The array which we want to split\n",
    "    train_val_idx_GoogleNet,\n",
    "    # Specify proportion of the dataset that should be allocated for the validation set \n",
    "    test_size = val_size_GoogleNet / (train_size_GoogleNet + val_size_GoogleNet),  \n",
    "    # Ensure class distribution is preserved for both the training and validation set\n",
    "    stratify = [targets_GoogleNet[i] for i in train_val_idx_GoogleNet],\n",
    "    # random seed for reproducibility\n",
    "    random_state = 42  \n",
    ")\n",
    "\n",
    "# Creating subsets for each split\n",
    "train_dataset_GoogleNet = Subset(dataset_GoogleNet, train_idx_GoogleNet)\n",
    "validation_dataset_GoogleNet = Subset(dataset_GoogleNet, val_idx_GoogleNet)\n",
    "test_dataset_GoogleNet = Subset(dataset_GoogleNet, test_idx_GoogleNet)\n",
    "\n",
    "# Creating data loaders that help iterate through the dataset in batches during training, validation and testing.\n",
    "# Using a batch size of 16 everywhere and only shuffling during training and not validation or testing.\n",
    "train_loader_GoogleNet = DataLoader(train_dataset_GoogleNet, batch_size=16, shuffle=True)\n",
    "validation_loader_GoogleNet = DataLoader(validation_dataset_GoogleNet, batch_size=16, shuffle=False)\n",
    "test_loader_GoogleNet = DataLoader(test_dataset_GoogleNet, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained GoogLeNet model\n",
    "googlenet_model = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(googlenet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of GoogleNet model\n",
    "# Input size of images would be a batch size of 16, RGB channels of 3, Height of 224 and Width of 224\n",
    "summary(googlenet_model, input_size=(16, 3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for the 3 classes: benign, malignant, normal\n",
    "num_classes = 3\n",
    "googlenet_model.fc = nn.Linear(googlenet_model.fc.in_features, num_classes)\n",
    "googlenet_model = googlenet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_googlenet_model, test_accuracies_googlenet_model, validation_accuracies_googlenet_model, train_losses_googlenet_model, test_losses_googlenet_model, validation_losses_googlenet_model, all_test_labels_googlenet_model, all_test_predictions_googlenet_model = train_and_evaluate(model = googlenet_model, model_name = \"GoogleNet_Model\", train_loader = train_loader_GoogleNet, validation_loader = validation_loader_GoogleNet, test_loader = test_loader_GoogleNet, epochs = 10, lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies_googlenet_model, label='Train Accuracy')\n",
    "plt.plot(test_accuracies_googlenet_model, label='Test Accuracy')\n",
    "plt.plot(validation_accuracies_googlenet_model, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training, Validation and Test Accuracies of GoogleNet Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Training, Validation and Test Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_googlenet_model, label='Train Loss')\n",
    "plt.plot(test_losses_googlenet_model, label='Test Loss')\n",
    "plt.plot(validation_losses_googlenet_model, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation and Test Losses of GoogleNet Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T12:27:39.406860Z",
     "iopub.status.busy": "2024-04-03T12:27:39.406217Z",
     "iopub.status.idle": "2024-04-03T12:27:39.411460Z",
     "shell.execute_reply": "2024-04-03T12:27:39.410536Z",
     "shell.execute_reply.started": "2024-04-03T12:27:39.406831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining dictionary of hyperparameters containing:\n",
    "# Learning rate - The learning rate of our Adam optimizer\n",
    "# Dropout rate - The dropout rate applied to our Adam optimizer\n",
    "# fc_units - The number of output features/neurons in the fully connected layer\n",
    "\n",
    "hyperparameters = {\n",
    "    'learning_rate': [1e-3, 1e-4, 1e-5],\n",
    "    'dropout_rate': [0.25, 0.5, 0.75],\n",
    "    'fc_units': [64, 128, 256]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T12:27:40.758734Z",
     "iopub.status.busy": "2024-04-03T12:27:40.758384Z",
     "iopub.status.idle": "2024-04-03T12:27:40.776933Z",
     "shell.execute_reply": "2024-04-03T12:27:40.776070Z",
     "shell.execute_reply.started": "2024-04-03T12:27:40.758707Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_new(model, train_loader, validation_loader, test_loader, epochs=10, lr=0.0001, save_path='best_model.pt'):\n",
    "    \n",
    "    # Move device to GPU if available, else CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Computes Loss Function using Cross Entropy Loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    # Initialize Adam Optimizer with certain parameters \n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           # Set learning rate of the optimizer\n",
    "                           lr=lr,\n",
    "                           # Set L2 regularization to the model's weights during optimization\n",
    "                           weight_decay=1e-4, \n",
    "                           # Defining beta1 (first moment) as 0.9 and beta2 (second moment) as 0.999\n",
    "                           betas=(0.9, 0.999),\n",
    "                           # Epsilon to ensure numerical stability during optimization\n",
    "                           eps=1e-8,\n",
    "                           # Adopting AMSGrad variant of the Adam optimizer\n",
    "                           amsgrad=True)\n",
    "\n",
    "    # Variable to keep track of the best validation accuracy\n",
    "    best_validation_accuracy = 0  \n",
    "    \n",
    "    # Store various metrics in form of dictionary. These metrics are as follows:\n",
    "    # best_validation_accuracy: Highest validation accuracy achieved during the training process \n",
    "    # best_validation_loss: Lowest validation loss achieved during the training process\n",
    "    # corresponding_test_accuracy: Test accuracy corresponding to the best validation accuracy\n",
    "    # corresponding_test_loss: Test loss corresponding to the best validation loss\n",
    "    # final_train_accuracy: Final training accuracy achieved at the end of the training process\n",
    "    # final_train_loss: Final training loss achieved at the end of the training process\n",
    "    metrics = {\n",
    "        'best_validation_accuracy': 0,\n",
    "        'best_validation_loss': float('inf'),\n",
    "        'corresponding_test_accuracy': 0,\n",
    "        'corresponding_test_loss': float('inf'),\n",
    "        'final_train_accuracy': 0,\n",
    "        'final_train_loss': float('inf'),\n",
    "    }\n",
    "\n",
    "    # Running the algorithm for specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Set the model to train mode\n",
    "        model.train()\n",
    "                \n",
    "        # Keeps track of training loss\n",
    "        train_loss = 0\n",
    "        \n",
    "        # Correct_train keeps track of the number of correctly predicted samples during training\n",
    "        correct_train = 0\n",
    "        \n",
    "        # Total_train keeps track of the number of the total number of training samples processed so far \n",
    "        total_train = 0\n",
    "            \n",
    "        # For each input data and label in training dataset\n",
    "        for inputs, labels in train_loader:\n",
    "            \n",
    "            # Move it to the right device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Set all calculated gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Trigger a forward pass through the neural network\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compare the outputs (predictions made by the model) and the labels (ground truth data) wrt to loss function\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Compute the gradients of the loss with respect to all trainable parameters in the model.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the model parameters based on the computed gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulates the value of the loss incurred in the current batch to the overall training loss.\n",
    "            # Note: .item() extracts scalar value\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Obtain the class predicted by the model\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update total_train to keep track of the total number of training samples processed so far\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            # Update correct_train to keep track of the number of correctly predicted samples in the current batch\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate train_accuracy\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "                \n",
    "        # Calculate the average training loss\n",
    "        train_loss_avg = train_loss / len(train_loader)\n",
    "\n",
    "        \n",
    "        \n",
    "        ## VALIDATION\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Correct_validation keeps track of the number of correctly predicted samples during validation\n",
    "        correct_validation = 0\n",
    "        \n",
    "        # Total_validation keeps track of the number of total samples during validation\n",
    "        total_validation = 0\n",
    "        \n",
    "        # Validation_loss keeps track of total loss during evaluation on the validation set\n",
    "        validation_loss = 0\n",
    "        \n",
    "        # During validation, we don't need to utilize gradient\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # For each input data and label in validation dataset\n",
    "            for inputs, labels in validation_loader:\n",
    "                \n",
    "                # Move it to the right device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Trigger a forward pass through the neural network\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compare the outputs (predictions made by the model) and the labels (ground truth data) wrt to loss function\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Accumulates the value of the loss incurred in the current batch to the overall validation loss.\n",
    "                # Note: .item() extracts scalar value\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "                # Obtain the class predicted by the model\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Update total_validation to keep track of the total number of validation samples processed so far\n",
    "                total_validation += labels.size(0)\n",
    "                \n",
    "                # Update correct_validation to keep track of the number of correctly predicted samples in the current batch\n",
    "                correct_validation += (predicted == labels).sum().item()\n",
    "            \n",
    "        # Calculate validation_accuracy\n",
    "        validation_accuracy = 100 * correct_validation / total_validation\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        validation_loss_avg = validation_loss / len(validation_loader)\n",
    "        \n",
    "        \n",
    "        ## TESTING\n",
    "        \n",
    "        \n",
    "        # Keeps track of testing loss\n",
    "        test_loss = 0 \n",
    "        \n",
    "        # Keeps track of the number of correctly predicted samples during testing\n",
    "        correct_test = 0\n",
    "        \n",
    "        # Total_test keeps track of the number of the total number of testing samples processed so far \n",
    "        total_test = 0\n",
    "        \n",
    "        # During testing, we don't need to utilize gradient\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # For each input data and label in test dataset\n",
    "            for inputs, labels in test_loader:\n",
    "                \n",
    "                # Move it to the right device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Trigger a forward pass through the neural network\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compare the outputs (predictions made by the model) and the labels (ground truth data) wrt to loss function\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Accumulates the value of the loss incurred in the current batch to the overall testing loss.\n",
    "                # Note: .item() extracts scalar value\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Obtain the class predicted by the model\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Update total_test to keep track of the total number of testing samples processed so far\n",
    "                total_test += labels.size(0)\n",
    "                \n",
    "                # Append the testing loss to correct_test list to monitor it over epochs\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "            \n",
    "        # Calculate testing accuracy\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        \n",
    "        # Calculate testing loss\n",
    "        test_loss_avg = test_loss / len(test_loader)\n",
    "\n",
    "        \n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            \n",
    "            # Update best_validation_accuracy as better validation accuracy has been found\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "            \n",
    "            # Save the model weights\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "            # Update metrics with the new best values\n",
    "            metrics.update({\n",
    "                'best_validation_accuracy': validation_accuracy,\n",
    "                'best_validation_loss': validation_loss_avg,\n",
    "                'corresponding_test_accuracy': test_accuracy,\n",
    "                'corresponding_test_loss': test_loss_avg,\n",
    "            })\n",
    "\n",
    "        # Always update the Final training accuracy and final training loss of the model after each epoch\n",
    "        metrics.update({\n",
    "            'final_train_accuracy': train_accuracy,\n",
    "            'final_train_loss': train_loss_avg,\n",
    "        })\n",
    "\n",
    "        # Print necessary information after each epoch ends\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Validation Loss: {validation_loss_avg:.4f}, \"\n",
    "              f\"Test Loss: {test_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Validation Accuracy: {validation_accuracy:.2f}%, \"\n",
    "              f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        print(\"--------------------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    # After the loop, save the path in metrics for reference\n",
    "    metrics['save_path'] = save_path\n",
    "    \n",
    "    # Return the metrics dictionary\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T12:27:40.036189Z",
     "iopub.status.busy": "2024-04-03T12:27:40.035831Z",
     "iopub.status.idle": "2024-04-03T12:27:40.045623Z",
     "shell.execute_reply": "2024-04-03T12:27:40.044618Z",
     "shell.execute_reply.started": "2024-04-03T12:27:40.036162Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_search(hyperparameters, num_trials, base_save_path='weights'):\n",
    "    \n",
    "    # If 'weights' folder does not exist, create it\n",
    "    if not os.path.exists(base_save_path):\n",
    "        os.makedirs(base_save_path)\n",
    "\n",
    "    # Store performance metrics of each trial\n",
    "    results = []\n",
    "    \n",
    "    # Keeps track of the highest validation accuracy achieved among all trials\n",
    "    best_validation_accuracy = 0\n",
    "    \n",
    "    # Stores the file path of the best-performing model\n",
    "    best_model_path = \"\"\n",
    "\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        # Randomly sample hyperparameters from the provided hyperparameter dictionary\n",
    "        lr = random.choice(hyperparameters['learning_rate'])\n",
    "        dropout = random.choice(hyperparameters['dropout_rate'])\n",
    "        fc_units = random.choice(hyperparameters['fc_units'])\n",
    "        \n",
    "        # Define the save path for the current trial's best model\n",
    "        save_path = os.path.join(base_save_path, f'best_model_trial_{trial+1}.pt')\n",
    "        \n",
    "        print(f\"Trial {trial+1}: Training with lr={lr}, dropout={dropout}, fc_units={fc_units}\")\n",
    "        \n",
    "        # Initialize the model with particular dropout rate and fc_units\n",
    "        model = CNN_for_LungCancer(dropout_rate = dropout, fc_units = fc_units)\n",
    "        \n",
    "        # Call the train_and_evaluate_new function with the chosen hyperparameters\n",
    "        metrics = train_and_evaluate_new(model, train_loader, validation_loader, test_loader, epochs=10, lr=lr, save_path=save_path)\n",
    "        \n",
    "        # Append metrics to results list\n",
    "        results.append(metrics)\n",
    "        \n",
    "        # Update the path of the best model if the current model performence is better\n",
    "        if metrics['best_validation_accuracy'] > best_validation_accuracy:\n",
    "            best_validation_accuracy = metrics['best_validation_accuracy']\n",
    "            best_model_path = metrics['save_path']\n",
    "    \n",
    "    print(f\"Best model saved at: {best_model_path}\")\n",
    "    return results, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T12:27:41.538345Z",
     "iopub.status.busy": "2024-04-03T12:27:41.537488Z",
     "iopub.status.idle": "2024-04-03T12:45:21.290757Z",
     "shell.execute_reply": "2024-04-03T12:45:21.289786Z",
     "shell.execute_reply.started": "2024-04-03T12:27:41.538313Z"
    }
   },
   "outputs": [],
   "source": [
    "results, best_model_path = random_search(hyperparameters, num_trials = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the accuracy and loss obtained for all trials of hyperparameter search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T12:45:21.292769Z",
     "iopub.status.busy": "2024-04-03T12:45:21.292399Z",
     "iopub.status.idle": "2024-04-03T12:45:21.899822Z",
     "shell.execute_reply": "2024-04-03T12:45:21.898940Z",
     "shell.execute_reply.started": "2024-04-03T12:45:21.292743Z"
    }
   },
   "outputs": [],
   "source": [
    "train_accuracies = np.array([res['final_train_accuracy'] for res in results])\n",
    "validation_accuracies = np.array([res['best_validation_accuracy'] for res in results])\n",
    "test_accuracies = np.array([res['corresponding_test_accuracy'] for res in results])\n",
    "\n",
    "train_losses = np.array([res['final_train_loss'] for res in results])\n",
    "validation_losses = np.array([res['best_validation_loss'] for res in results])\n",
    "test_losses = np.array([res['corresponding_test_loss'] for res in results])\n",
    "\n",
    "trials = np.arange(1, len(results) + 1)\n",
    "\n",
    "# Identifying the best trial based on validation accuracy\n",
    "best_trial_acc = np.argmax(validation_accuracies) + 1\n",
    "best_acc = validation_accuracies[best_trial_acc - 1]\n",
    "\n",
    "# Plotting accuracies (training, validation, test)\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(trials, train_accuracies, 'o-', label='Train Acc', color='blue')\n",
    "plt.plot(trials, validation_accuracies, 's--', label='Valid Acc', color='orange')\n",
    "plt.plot(trials, test_accuracies, '^-.', label='Test Acc', color='green')\n",
    "plt.axvline(x=best_trial_acc, color='gray', linestyle='--', label=f'Best Trial #{best_trial_acc}')\n",
    "plt.title('Accuracy Across Trials')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting losses (training, validation, and test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(trials, train_losses, 'o-', label='Train Loss', color='blue')\n",
    "plt.plot(trials, validation_losses, 's--', label='Validation Loss', color='orange')\n",
    "plt.plot(trials, test_losses, '^-.', label='Test Loss', color='green')\n",
    "plt.axvline(x=best_trial_acc, color='gray', linestyle='--', label=f'Best Trial #{best_trial_acc}')\n",
    "plt.title('Loss Across Trials')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best Trial: {best_trial_acc} with Validation Accuracy: {best_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model and conducting Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented transformation with horizontal flip and random rotation\n",
    "augmented_transform = transforms.Compose([\n",
    "    \n",
    "    # Resize input images to a fixed size of 224x224 pixels\n",
    "    transforms.Resize((224, 224)),\n",
    "    \n",
    "    # Randomly flips the images horizontally with a probability of 1.0\n",
    "    transforms.RandomHorizontalFlip(p=1.0), \n",
    "    \n",
    "    # Randomly rotate images in the range of -15 to +15 degrees\n",
    "    transforms.RandomRotation(degrees=15), \n",
    "    \n",
    "    # Converts the augmented images into PyTorch tensors\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Standardize input data by subtracting the mean and dividing by the standard deviation along each channel (RGB)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the dataset from local folder, applying transformations this time\n",
    "dataset = datasets.ImageFolder(root='dataset', transform = augmented_transform)\n",
    "\n",
    "# Splitting the dataset - 70% for training, 15% for validation and the rest 15% for testing\n",
    "train_size = int(0.7 * len(dataset)) \n",
    "val_size = int(0.15 * len(dataset)) \n",
    "test_size = len(dataset) - train_size - val_size \n",
    "\n",
    "# Extracting labels from the dataset\n",
    "targets = [s[1] for s in dataset.samples]  \n",
    "\n",
    "# Splitting the dataset into 2 sets: train+val and test sets\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    # The array which we want to split\n",
    "    range(len(targets)),\n",
    "    # Specify proportion of the dataset that should be allocated for the test set \n",
    "    test_size= test_size/len(dataset), \n",
    "    # Ensure class distribution is preserved in both the training+validation and testing sets\n",
    "    stratify=targets,\n",
    "    # random seed for reproducibility\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# Splitting the train+val further into 2 sets: training and validation sets\n",
    "train_idx, val_idx = train_test_split(\n",
    "    # The array which we want to split\n",
    "    train_val_idx,\n",
    "    # Specify proportion of the dataset that should be allocated for the validation set \n",
    "    test_size=val_size / (train_size + val_size),  \n",
    "    # Ensure class distribution is preserved for both the training and validation set\n",
    "    stratify=[targets[i] for i in train_val_idx],\n",
    "    # random seed for reproducibility\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# Creating subsets for each split\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "validation_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "# Creating data loaders that help iterate through the dataset in batches during training, validation and testing.\n",
    "# Using a batch size of 16 everywhere and only shuffling during training and not validation or testing.\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_inference = CNN_for_LungCancer(dropout_rate=0.5, fc_units=64)\n",
    "cnn_model_inference.load_state_dict(torch.load('model/lung_cancer_classification_cnn_model.pth'))\n",
    "cnn_model_inference.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_model_inference = models.resnet152(pretrained=True)\n",
    "\n",
    "# num_features = resnet_model_inference.fc.in_features\n",
    "# resnet_model_inference.fc = nn.Linear(num_features, 3)\n",
    "# resnet_model_inference = resnet_model_inference.to(device)\n",
    "# resnet_model_inference.load_state_dict(torch.load('model/lung_cancer_classification_cnn_model.pth'))\n",
    "# resnet_model_inference.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(model, test_loader):\n",
    "    \n",
    "    # Move device to GPU if available, else CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Computes Loss Function using Cross Entropy Loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Keeps track of testing loss\n",
    "    test_loss = 0 \n",
    "    # Keeps track of the number of correctly predicted samples during testing\n",
    "    correct_test = 0\n",
    "    # Total_test keeps track of the number of the total number of testing samples processed so far \n",
    "    total_test = 0\n",
    "    \n",
    "    # During testing, we don't need to utilize gradient\n",
    "    with torch.no_grad():\n",
    "        # For each input data and label in test dataset\n",
    "        for inputs, labels in test_loader:\n",
    "            # Move data to the right device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Trigger a forward pass through the neural network\n",
    "            outputs = model(inputs)\n",
    "            # Compare the outputs (predictions made by the model) and the labels (ground truth data) wrt to loss function\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Accumulates the value of the loss incurred in the current batch to the overall testing loss.\n",
    "            test_loss += loss.item()\n",
    "            # Obtain the class predicted by the model\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Update total_test to keep track of the total number of testing samples processed so far\n",
    "            total_test += labels.size(0)\n",
    "            # Update correct_test to keep track of the number of correctly predicted samples in the current batch\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate testing accuracy\n",
    "    final_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = (correct_test/total_test) * 100\n",
    "    \n",
    "    print(f\"Test Loss: {final_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "                                      \n",
    "    return final_test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = testing_model(model = inference_model, test_loader = test_loader_for_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_accuracy = testing_model(model = resnet_model_inference, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to set the seed\n",
    "# def set_seed(seed=42):\n",
    "#     \"\"\"Sets various seed for reproducibility (especially useful when checking whether saved trained model matches with that loaded on inference).\"\"\"\n",
    "    \n",
    "    \n",
    "#     random.seed(seed)\n",
    "    \n",
    "#     # Sets the seed for NumPy's random number generator\n",
    "#     np.random.seed(seed)\n",
    "    \n",
    "#     # Sets the seed for generating random numbers in PyTorch on CPU and GPU.\n",
    "#     torch.manual_seed(seed)\n",
    "    \n",
    "#     # Ensure seed is set for all CUDA devices for operations that use PyTorch with CUDA\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "#     # Forces CuDNN to use deterministic algorithms\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "#     # Disables the CuDNN benchmarking feature, which dynamically finds the most efficient algorithms for your specific operations\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# # Call set_seed at the beginning of your script with a particular seed, say 42. \n",
    "# set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "def save_classification_report_image(report, filename):\n",
    "    # Parse the classification report string\n",
    "    lines = report.split('\\n')\n",
    "    data = [line.split() for line in lines[2:-3]]\n",
    "\n",
    "    # Extract class names and metrics\n",
    "    classes = [row[0] for row in data]\n",
    "    metrics = np.array(data)[:, 1:].astype(float)\n",
    "\n",
    "    # Plot classification report as a heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(metrics, cmap='viridis', aspect='auto')\n",
    "    plt.title('Classification Report Heatmap')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xticks(np.arange(len(classes)), ['Precision', 'Recall', 'F1-score', 'Support'])\n",
    "    plt.yticks(np.arange(len(classes)), classes)\n",
    "    plt.colorbar(label='Metric Value')\n",
    "\n",
    "    # Save the plot as an image\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Example classification report\n",
    "\n",
    "# Save the classification report as an image\n",
    "save_classification_report_image(report, 'classification_report.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_classification_report_image(report, filename):\n",
    "    # Parse the classification report string\n",
    "    lines = report.strip().split('\\n')\n",
    "\n",
    "    # Extract class names and metrics\n",
    "    data = [line.split() for line in lines[2:] if line.strip() and not line.strip().startswith(('micro', 'macro', 'weighted'))]  # Skip empty lines and macro/weighted averages\n",
    "\n",
    "    classes = []\n",
    "    metrics = []\n",
    "\n",
    "    for row in data:\n",
    "        if len(row) >= 5:\n",
    "            classes.append(row[0])\n",
    "            metrics.append(row[1:])\n",
    "\n",
    "    # Convert metrics to numpy array\n",
    "    metrics = np.array(metrics).astype(float)\n",
    "\n",
    "    # Plot classification report as a heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(metrics, cmap='viridis', aspect='auto')\n",
    "    plt.title('Classification Report Heatmap')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xticks(np.arange(4), ['Precision', 'Recall', 'F1-score', 'Support'])\n",
    "    plt.yticks(np.arange(len(classes)), classes)\n",
    "    plt.colorbar(label='Metric Value')\n",
    "\n",
    "    # Save the plot as an image\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Example classification report\n",
    "report = \"\"\"\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "     class 0       0.75      0.60      0.67        10\n",
    "     class 1       0.80      0.89      0.84        19\n",
    "     class 2       0.50      0.50      0.50         6\n",
    "\n",
    "    accuracy                           0.76        35\n",
    "   macro avg       0.68      0.66      0.67        35\n",
    "weighted avg       0.75      0.76      0.75        35\n",
    "\"\"\"\n",
    "\n",
    "# Save the classification report as an image\n",
    "save_classification_report_image(report, 'classification_report.png')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 672399,
     "sourceId": 1183191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
