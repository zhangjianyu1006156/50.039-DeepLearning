Training accuracies: [52.41199478487614, 69.49152542372882, 73.40286831812256, 74.70664928292047, 75.88005215123859, 77.3142112125163, 75.22816166883963, 80.1825293350717, 78.6179921773142, 79.92177314211213, 79.13950456323337, 80.70404172099087, 82.65971316818775, 84.61538461538461, 83.70273794002608, 82.13820078226858, 83.83311603650587, 83.05084745762711]
Testing accuracies: [39.75903614457831, 42.7710843373494, 44.57831325301205, 45.78313253012048, 42.7710843373494, 42.7710843373494, 45.78313253012048, 44.57831325301205, 44.57831325301205, 47.59036144578313, 47.59036144578313, 45.78313253012048, 48.795180722891565, 47.59036144578313, 49.397590361445786, 49.397590361445786, 49.397590361445786]
Validation accuracies: [42.073170731707314, 40.853658536585364, 41.46341463414634, 41.46341463414634, 41.46341463414634, 43.292682926829265, 41.46341463414634, 41.46341463414634, 41.46341463414634, 41.46341463414634, 44.51219512195122, 42.073170731707314, 42.68292682926829, 43.90243902439025, 43.292682926829265, 42.073170731707314, 43.292682926829265, 45.73170731707317]
Training loses: [0.1287748398155802, 0.053898940710092165, 0.0319871823497427, 0.027258946282219972, 0.023800749204787683, 0.024985186998997558, 0.026434116246592667, 0.02032802577782099, 0.02259216370132183, 0.02025234856329108, 0.020329547700384865, 0.021671882326902255, 0.020796798010350257, 0.01629019143466495, 0.01975359008065425, 0.02314646362154033, 0.015909601211963793, 0.01835780120462813]
Validation loses: [0.6377493862278205, 0.6152082041275403, 0.5807221507237963, 0.580442986212486, 0.6210001677521004, 0.5793348994136842, 0.5460897437797105, 0.5336718224296885, 0.5286629594061986, 0.5294518372244087, 0.49717512209553366, 0.4955232714818529, 0.4844426044747849, 0.4987637563185258, 0.4979882831415854, 0.4950961711978124, 0.4972516997786593, 0.4870952101778393]
Testing loses: [0.6592385749186366, 0.6435316515362953, 0.6113977767219229, 0.587278594655439, 0.625641915423811, 0.5929246736952096, 0.551220235745769, 0.5387731563946432, 0.5184477518412692, 0.5353624328108858, 0.5218610566509656, 0.4924695432678727, 0.4844920654927403, 0.5056453893992526, 0.5236725078141394, 0.49606525602419516, 0.5037912317543976]










              precision    recall  f1-score   support

           0       0.56      0.83      0.67        18
           1       1.00      0.07      0.13        85
           2       0.46      0.97      0.62        63

    accuracy                           0.49       166
   macro avg       0.67      0.62      0.47       166
weighted avg       0.75      0.49      0.38       166

